{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This is a simplified version of my 18th place solution in the **Shopee - Price Match Guarantee** contest\n## I replaced my image models with resnet18 to showcase that even a very basic model could do well and was enough to score a silver medal in this competition","metadata":{}},{"cell_type":"markdown","source":"# The outline of my approach\n\n### Step 1 training \nI used arcface for all my training, and fine tune pretrained models with it for a few epochs. For image I tried resnet, efficient net and nfnet. The nfnet worked the best for me so that’s in my final solution. The resnet18 I used in the toy solution just to show a very basic model can work too. \n\nFor text I found that language model pretrained on Indonesian language worked the best.\n\n### Step 2 Embeddings and similarities \nFor each model I first generate embedddings and then calculate the full cosine similarity matrix.\n\n### Step 3 Combine the model outputs\nI combine the matrices from the previous step with formula D = 1 - (1 - D<sub>TFIDF</sub>) * (1 - D<sub>Resnet</sub>) * (1 - D<sub>BERT</sub>)\n\nThis I found works much better than alternatives of taking mean or max.\n\n### Step 4 Rerank\nI replace the predictions of each row with an average of predictions of its nearest neighbors. I set threshold for “nearest” so that 4 neighbors are used on average (found experimentally)\n\nIt helps the score a bit.\n\n### Step 5 force groups into a desired distribution \nThis was a largest single change I made, jumping my score from .739 to .759\nI nicknamed it “chiseling” the idea is: I first make an educated guess that the distribution of group targets in the test data is similar to the one in train. Then I make my solution to have the same shape.\n\nI first decide that groups with 2 elements are going to be those where the third largest element is the lowest. Then I follow the same logic for all the sizes up to 50.\n\n### No thresholds!\nEarly in the competition I followed the public approaches of selecting elements to pick based on the hard coded threshold - this had to be tuned for test data separately and eat into your submissions limit and time. (Especially with multiple models). When I moved to make decisions based on the data distribution instead, it made the code much more resilient with less need for tuning when changing/adding models.\n\n","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *\nfrom tqdm.notebook import tqdm\nimport sklearn.feature_extraction.text\nfrom transformers import (BertTokenizer, AutoConfig, AutoModel)\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"_uuid":"ff5bb67f-2120-4e43-9194-3c81163b88b8","_cell_guid":"77132214-d48c-4b70-be5e-8dedc6678024","papermill":{"duration":3.516665,"end_time":"2021-04-22T16:24:15.53885","exception":false,"start_time":"2021-04-22T16:24:12.022185","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = Path('../input/shopee-product-matching')\n\nBERT_PATH = '../input/bertindo15g'\nbert_model_file = '../input/shopee-small-models/bert_indo_val0.pth'\n\nimage_model_file = '../input/shopee-small-models/resnet18val0.pth'\n","metadata":{"_uuid":"1cc2236b-bfee-4b58-93e0-f7604caffdae","_cell_guid":"e349984e-3a5a-4d8b-aac6-11a3ac1a1eee","collapsed":false,"papermill":{"duration":0.057025,"end_time":"2021-04-22T16:24:17.09172","exception":false,"start_time":"2021-04-22T16:24:17.034695","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this is used for reranking, controls how many neighbours on average are considered\nRECIPROCAL_PER_ROW = 4.2","metadata":{"_uuid":"cb2c5e2d-2579-4194-b8d4-d540e649393a","_cell_guid":"c4ef6d88-7b51-4dd0-82f1-4a18143094c8","collapsed":false,"papermill":{"duration":0.062695,"end_time":"2021-04-22T16:24:16.781329","exception":false,"start_time":"2021-04-22T16:24:16.718634","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bert Model","metadata":{"_uuid":"f73d5522-1e48-490e-ae30-a465a8430059","_cell_guid":"3a6de183-f534-43ea-8221-0b42a29d2262","papermill":{"duration":0.020586,"end_time":"2021-04-22T16:24:19.821277","exception":false,"start_time":"2021-04-22T16:24:19.800691","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"class BertTextModel(nn.Module):\n    def __init__(self, bert_model):\n        super().__init__()\n        self.bert_model = bert_model\n    def forward(self, x):\n        output = self.bert_model(*x)\n        return output.last_hidden_state[:,0,:]","metadata":{"_uuid":"8853c86b-0515-46c6-9d1c-3356d8ce08c5","_cell_guid":"872258eb-cdba-48f0-9529-bd7a8827b6dd","collapsed":false,"papermill":{"duration":0.099852,"end_time":"2021-04-22T16:24:19.942342","exception":false,"start_time":"2021-04-22T16:24:19.84249","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_bert_model(fname):\n    model = AutoModel.from_config(AutoConfig.from_pretrained(BERT_PATH))\n    state = torch.load(fname)\n    model.load_state_dict(state)\n    return BertTextModel(model).cuda().eval()","metadata":{"_uuid":"f63672bb-da68-476c-b0aa-93eec8da7f6d","_cell_guid":"f480f4ca-b62b-45fc-b893-64082dd110e9","collapsed":false,"papermill":{"duration":0.061493,"end_time":"2021-04-22T16:24:24.081144","exception":false,"start_time":"2021-04-22T16:24:24.019651","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataloader for Bert","metadata":{}},{"cell_type":"code","source":"#Taken from https://www.kaggle.com/c/shopee-product-matching/discussion/233605#1278984\ndef string_escape(s, encoding='utf-8'):\n    return s.encode('latin1').decode('unicode-escape').encode('latin1').decode(encoding)\n\nclass TitleTransform(Transform):\n    def __init__(self):\n        super().__init__()\n        self.tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n               \n    def encodes(self, row):\n        text = row.title\n        text=string_escape(text)\n        encodings = self.tokenizer(text, padding = 'max_length', max_length=100, truncation=True,return_tensors='pt')\n        keys =['input_ids', 'attention_mask', 'token_type_ids'] \n        return tuple(encodings[key].squeeze() for key in keys)\n\ndef get_text_dls():\n    tfm = TitleTransform()\n\n    data_block = DataBlock(\n        blocks = (TransformBlock(type_tfms=tfm), \n                  CategoryBlock(vocab=train_df.label_group.to_list())),\n        splitter=ColSplitter(),\n        get_y=ColReader('label_group'),\n        )\n    return  data_block.dataloaders(train_df, bs=256)","metadata":{"_uuid":"68f265b5-bd46-4175-a102-939d0a16eb63","_cell_guid":"e9c9b3c7-ac0c-4927-a99f-93492c91bb43","collapsed":false,"papermill":{"duration":3.955284,"end_time":"2021-04-22T16:24:23.998148","exception":false,"start_time":"2021-04-22T16:24:20.042864","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TFIDF","metadata":{"_uuid":"857bee21-9439-48ef-92e6-0ab26dd55224","_cell_guid":"4b52da70-05a3-4400-817a-44eaada28568","papermill":{"duration":0.020882,"end_time":"2021-04-22T16:24:24.198936","exception":false,"start_time":"2021-04-22T16:24:24.178054","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"def csr_matrix_to_tensor(csr):\n    coo = csr.tocoo()\n    t = torch.sparse_coo_tensor([coo.row, coo.col], coo.data, csr.shape).cuda()\n    return t\n\ndef get_tfid_embs(data, idxs):\n    sk_model = sklearn.feature_extraction.text.TfidfVectorizer(stop_words='english', binary=True, max_features=25_000)\n    text_embeddings =sk_model.fit_transform(data.title)\n    text_embeddings =text_embeddings[idxs]\n    return text_embeddings\n\ndef generate_tfid_D(text_embeddings, out):\n    emb_size = text_embeddings.shape[0]\n    \n    sparse_embs = csr_matrix_to_tensor(text_embeddings)\n    step = 100\n    for chunk_start in range(0, emb_size, step):\n        chunk_end = min(chunk_start+step, emb_size)\n        chunk = text_embeddings[chunk_start:chunk_end]\n        chunk = csr_matrix_to_tensor(chunk).to_dense()\n        tmp = sparse_embs @ chunk.T\n        tmp.clip_(0,1)\n        out[chunk_start:chunk_end]=tmp.half().T","metadata":{"_uuid":"4bb74277-885b-4e56-9762-ad998b0aa4e6","_cell_guid":"b774ae0e-c957-443d-b064-0f36b9a2c23c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## IMAGE","metadata":{"_uuid":"cdce4831-10d8-4d5d-a857-ba876826f0f9","_cell_guid":"86805bd9-cbac-4ced-a2b5-f5069226dbca","papermill":{"duration":0.020882,"end_time":"2021-04-22T16:24:24.198936","exception":false,"start_time":"2021-04-22T16:24:24.178054","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"class ResnetModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.body = create_body(resnet18, cut=-2, pretrained=False)\n        self.after_conv=nn.Sequential(\n            AdaptiveConcatPool2d(),\n            Flatten(),\n            nn.BatchNorm1d(1024)\n        )\n    def forward(self, x):\n        x = self.body(x)\n        return self.after_conv(x)\n        ","metadata":{"_uuid":"cde99e66-bdb6-4ab6-a2a6-782c592c1325","_cell_guid":"faafd9f9-9682-4fe0-b891-04bf57494c67","collapsed":false,"papermill":{"duration":0.060402,"end_time":"2021-04-22T16:24:24.280612","exception":false,"start_time":"2021-04-22T16:24:24.22021","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image_model(fname):\n    state_dict = torch.load(fname)\n    model = ResnetModel()\n    model.load_state_dict(state_dict)\n    model = model.eval().cuda()\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_file(row):\n    img =row.image\n    fn  = PATH/'train_images'/img\n    if not fn.is_file():\n        fn = PATH/'test_images'/img\n    return fn\n\ndef get_image_dls(size, bs):\n    data_block = DataBlock(blocks = (ImageBlock(), CategoryBlock(vocab=train_df.label_group.to_list())),\n                 splitter=ColSplitter(),\n                 get_y=ColReader('label_group'),\n                 get_x=get_img_file,\n                 item_tfms=Resize(size*2, resamples=(Image.BICUBIC,Image.BICUBIC)), \n                 batch_tfms=aug_transforms(size=size, min_scale=0.75)+[Normalize.from_stats(*imagenet_stats)],\n                 )\n    return data_block.dataloaders(train_df, bs=bs)\n\n","metadata":{"_uuid":"db236273-6853-4657-891d-806f53450f45","_cell_guid":"17aafba7-492b-44a6-8380-9e1867db732f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper code","metadata":{"_uuid":"11385402-719c-4535-9ccf-4d4773185f51","_cell_guid":"00b1b23c-8ce9-460c-a1c6-f573072e3590","papermill":{"duration":0.02188,"end_time":"2021-04-22T16:24:26.268339","exception":false,"start_time":"2021-04-22T16:24:26.246459","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"# Code used in the solution\n\ndef gen_sim_and(embs_list, res):\n    emb_size = len(embs_list[0])\n    step = 100\n    cache = torch.empty((step, emb_size), device = 'cuda', dtype=embs_list[0].dtype)\n    for embs in embs_list:\n        embs = embs.cuda()\n        for chunk_start in range(0, emb_size, step):\n            chunk_end = min(chunk_start+step, emb_size)\n            chunk=embs[chunk_start: chunk_end]\n            tmp = cache[:chunk_end-chunk_start]\n            torch.matmul(chunk, embs.T, out = tmp)\n            tmp.clip_(0,1)\n            tmp.mul_(-1)\n            tmp.add_(1)\n            res[chunk_start:chunk_end].mul_(tmp)\n    res.mul_(-1)\n    res.add_(1)\n\ndef reciprocal_probs(D, x, thresh):\n    neighb_cnt = torch.count_nonzero(D[x]>thresh)\n    if neighb_cnt > 50:\n        _,neighb= D[x].topk(50)\n    else:\n        neighb=torch.nonzero(D[x]>thresh) \n    DP = D[neighb]\n    DP = DP.mean(dim=0)\n    return DP\n\ndef find_threshold(D):\n    k=D.numel()-int(RECIPROCAL_PER_ROW*len(D))\n    threshold=D.view(-1).kthvalue(k).values\n    return threshold\n\ndef rerank(D):\n    if len(D)<4: threshold =0\n    else: \n        threshold = find_threshold(D[:20000])\n        print(\"threshold for rerank:\", threshold.item())\n    for i in range(len(D)):\n        D[i]=reciprocal_probs(D, i,threshold)\n\ndef dist_to_edges(dist):\n    res = []\n    K = min(51, len(dist))\n    for x in range(len(dist)):\n        vals, ys = dist[x].topk(K)\n        for v,y in zip(vals.tolist(),ys.tolist()):\n            res.append((x,y,v))\n    return sorted(res, key=lambda x: -x[2])\n\ndef get_group_probs(groups, D):\n    group_probs=[]\n    new_groups=[]\n    for x in range(len(groups)):\n        gr = groups[x]\n        gr_probs = D[x][gr]\n        with_prob =sorted(list(zip(gr, gr_probs)), key=lambda x: -x[1])\n        new_groups.append([wp[0] for wp in with_prob])\n        group_probs.append([wp[1]for wp in with_prob])\n    return new_groups, group_probs\n\ndef edges_to_groups(edges, N):\n    groups = [[] for i in range(N)]\n    groups_p = [[] for _ in range(N)]\n    for x,y,v in edges:\n        if len(groups[x])>=51: continue\n        groups[x].append(y)\n        groups_p[x].append(v)\n    return groups, groups_p\n\ndef add_target_groups(data_df, source_column='label_group', target_column='target'):\n    target_groups = data_df.groupby(source_column).indices\n    data_df[target_column]=data_df[source_column].map(target_groups)\n    return data_df\n\ndef add_splits(train_df, valid_group=0):\n    grouped = train_df.groupby('label_group').size()\n\n    labels, sizes =grouped.index.to_list(), grouped.to_list()\n\n    skf = StratifiedKFold(5)\n    splits = list(skf.split(labels, sizes))\n\n    group_to_split =  dict()\n    for idx in range(5):\n        labs = np.array(labels)[splits[idx][1]]\n        group_to_split.update(dict(zip(labs, [idx]*len(labs))))\n\n    train_df['split'] = train_df.label_group.replace(group_to_split)\n    train_df['is_valid'] = train_df['split'] == valid_group\n    return train_df\n\ndef embs_from_model(model, dl):\n    all_embs = []\n    all_ys=[]\n    for batch in tqdm(dl):\n        if len(batch) ==2:\n            bx,by=batch\n        else:\n            bx,=batch\n            by=torch.zeros(1)\n        with torch.no_grad():\n            embs = model(bx)\n            all_embs.append(embs.half())\n        all_ys.append(by)\n    all_embs = F.normalize(torch.cat(all_embs))\n    return all_embs, torch.cat(all_ys)\n\ndef get_targets_shape(train_df):\n    all_targets = add_target_groups(train_df).target.to_list()\n    all_targets_lens = [len(t) for t in all_targets]\n    targets_shape = []\n    for size in range(min(all_targets_lens), max(all_targets_lens)+1):\n        count = all_targets_lens.count(size) / len(all_targets)\n        targets_shape.append((size,count))\n    return targets_shape\n\ndef chisel(groups, groups_p, pos, target_count):\n    probs = []\n    groups_lens = [len(g)for g in groups]\n    current_count = groups_lens.count(pos)\n    if current_count >= target_count:\n\n        return\n    to_cut = target_count - current_count\n    for i in range(len(groups)):\n        if len(groups_p[i])>pos:\n            probs.append((i, groups_p[i][pos]))\n    probs.sort(key=lambda x:x[1])\n    for i in range(min(to_cut, len(probs))):\n        group_idx = probs[i][0] \n        groups[group_idx]=groups[group_idx][:pos]\n        groups_p[group_idx]=groups_p[group_idx][:pos]","metadata":{"_uuid":"c3e139d8-7fcc-49eb-a105-8186c83009bd","_cell_guid":"98e51efa-e6f6-41d6-b410-3f7dbc5a7e70","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Not used in solution, just for illustration purpose\ndef f1(tp, fp, num_tar):\n    return 2 * tp / (tp+fp+num_tar)\n\ndef build_from_pairs(pairs, target, display = True):\n    score =0\n    tp = [0]*len(target)\n    fp = [0]*len(target)\n    scores=[]\n    vs=[]\n    group_sizes = [len(x) for x in target]\n    for x, y, v in pairs:\n        group_size = group_sizes[x]\n        score -= f1(tp[x], fp[x], group_size)\n        if y in target[x]: tp[x] +=1\n        else: fp[x] +=1\n        score += f1(tp[x], fp[x], group_size) \n        scores.append(score / len(target))\n        vs.append(v)\n    if display:\n        plt.plot(scores)\n        am =torch.tensor(scores).argmax()\n        print(f'{scores[am]:.3f} at {am/len(target)} pairs or {vs[am]:.3f} threshold')\n    return scores\n\n\ndef score_distances(dist, targets, display=False):\n    triplets = dist_to_edges(dist)[:len(dist)*10]\n    return max(build_from_pairs(triplets, targets, display))\n\ndef score_group(group, target):\n    tp = len(set(group).intersection(set(target)))\n    return 2 * tp / (len(group)+len(target))\ndef score_all_groups(groups, targets):\n    scores = [score_group(groups[i], targets[i]) for i in range(len(groups))]\n    return sum(scores)/len(scores)\ndef show_groups(groups, targets):\n    groups_lens = [len(g)for g in groups]\n    targets_lens = [len(g) for g in targets]\n    plt.figure(figsize=(8,8)) \n    plt.hist((groups_lens,targets_lens) ,bins=list(range(1,52)), label=['preds', 'targets'])\n    plt.legend()\n    plt.title(f'score: {score_all_groups(groups, targets):.3f}')\n    plt.show()","metadata":{"_uuid":"6a85347d-9acd-437e-8567-71e044da67fb","_cell_guid":"2e3fae08-7cb5-43b0-872c-367511499168","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check on validation set","metadata":{"_uuid":"54e4613e-64d9-4b56-b738-4ab7ea379901","_cell_guid":"b62b7989-4eb5-411f-a08d-df78b33aea77","papermill":{"duration":0.02188,"end_time":"2021-04-22T16:24:26.268339","exception":false,"start_time":"2021-04-22T16:24:26.246459","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"train_df = pd.read_csv(PATH/'train.csv')\ntrain_df = add_splits(train_df)","metadata":{"_uuid":"39bae9ba-9280-42a9-80aa-cafa12a56b78","_cell_guid":"a12420b6-c806-485f-bf9d-f1cd04d35ce2","papermill":{"duration":2.666891,"end_time":"2021-04-22T16:24:19.779132","exception":false,"start_time":"2021-04-22T16:24:17.112241","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generating embeddings from Resnet and BERT","metadata":{}},{"cell_type":"code","source":"img_embs,ys = embs_from_model(load_image_model(image_model_file), get_image_dls(224,256).valid)\n\nbert_embs, ys = embs_from_model(load_bert_model(bert_model_file), get_text_dls().valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculating all the similiraties and combining them together\nThe formula I use is D = 1 - (1 - D<sub>TFIDF</sub>) * (1 - D<sub>Resnet</sub>) * (1 - D<sub>BERT</sub>)\nThe reason the code looks more complicated is that I can only fit a single 70Kx70K fp16 matrix in the memory, that's why why I do multiplications chunk by chunk inside the `gen_sim_and` function. I also use pytorch inplace operators like `mul_` not to allocate any additional memory","metadata":{}},{"cell_type":"code","source":"D = torch.empty((img_embs.shape[0], img_embs.shape[0]), device = 'cuda', dtype=torch.float16)\ntfid_embs = get_tfid_embs(train_df, train_df[train_df.is_valid].index.tolist())\ngenerate_tfid_D(tfid_embs,D)\nD.mul_(-1)\nD.add_(1)\ngen_sim_and([img_embs,bert_embs],D)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here is the score if we just used a fixed Threshold\nThe chart shows the competition metric depending on the number of edges we include in the submission and prints the maximum value","metadata":{}},{"cell_type":"code","source":"targets = [torch.where(t)[0].tolist() for t in ys[:,None]==ys[None,:]]\nscore_distances(D,targets, display=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here is the score after Reranking step:","metadata":{}},{"cell_type":"code","source":"rerank(D)\nscore_distances(D,targets, display=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### And here are the sizes of all the groups compared to the ground truth","metadata":{}},{"cell_type":"code","source":"edges = dist_to_edges(D)\ngroups, groups_p = edges_to_groups(edges[:6*len(D)], len(D))\n\nshow_groups(groups, targets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we perform the chisel step to match the two distributions\nNote the improved score, this effect is more pronounced on the test set where the initial grouping is further apart from the target","metadata":{}},{"cell_type":"code","source":"edges = dist_to_edges(D)\ngroups, groups_p = edges_to_groups(edges, len(D))\nfor pos, size_pct in get_targets_shape(train_df):\n    chisel(groups, groups_p, pos, int(size_pct * len(groups)))\nshow_groups(groups, targets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run on the test set\nsame as above, just without displaying stuff and deleting objects we no longer need to preserve memory","metadata":{"_uuid":"eb5fea9c-c0fe-4934-be60-a75c5962474a","_cell_guid":"ea45a659-b9da-4171-a51c-19378f4ccdbb","papermill":{"duration":0.021804,"end_time":"2021-04-22T16:24:26.476827","exception":false,"start_time":"2021-04-22T16:24:26.455023","status":"completed"},"tags":[],"trusted":true}},{"cell_type":"code","source":"test_df = pd.read_csv(PATH/'test.csv')","metadata":{"_uuid":"b67286d1-7737-4a27-9f27-0f895fae7bb9","_cell_guid":"85ab3f63-87f6-49f9-a644-184537e7620a","collapsed":false,"papermill":{"duration":0.063555,"end_time":"2021-04-22T16:24:26.562352","exception":false,"start_time":"2021-04-22T16:24:26.498797","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_embs,_ = embs_from_model(load_bert_model(bert_model_file), get_text_dls().test_dl(test_df))\n\nimg_embs,_ =embs_from_model(load_image_model(image_model_file), get_image_dls(224, 256).test_dl(test_df))","metadata":{"_uuid":"f9d641f6-bb96-47cd-adde-0ad20bfeae4e","_cell_guid":"e21bad7b-ce82-47b3-b07c-65efb1ed2c0f","collapsed":false,"papermill":{"duration":4.435158,"end_time":"2021-04-22T16:24:50.721083","exception":false,"start_time":"2021-04-22T16:24:46.285925","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfid_embs=  get_tfid_embs(pd.concat([test_df,train_df]), range(len(test_df)))","metadata":{"_uuid":"0f792ace-3bc2-4662-9542-3161bbb5a7ca","_cell_guid":"2db68fc0-37be-4eb4-8000-71506690c3cf","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_size = len(test_df)\nD = torch.empty((emb_size, emb_size), device = 'cuda', dtype=torch.float16)","metadata":{"_uuid":"624c96d0-926e-45bc-bb69-564bd68a5636","_cell_guid":"c03c66dd-b836-46f8-bf0a-a3c58705d44e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_tfid_D(tfid_embs,D)\ndel tfid_embs","metadata":{"_uuid":"6c3782c4-9a32-4b69-b3a1-900afb21ec05","_cell_guid":"7bd86236-78b4-455d-83c6-1150d41cf056","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"D.mul_(-1)\nD.add_(1)\ngen_sim_and([img_embs, bert_embs],D)","metadata":{"_uuid":"ec01d616-2114-4145-856b-91d259071fa3","_cell_guid":"aa36a1c6-139a-429e-b96c-fde25ea45995","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del img_embs, bert_embs","metadata":{"_uuid":"f2237491-5c06-4788-a71d-d778753453a6","_cell_guid":"6a97e111-87a5-418d-abe2-9cb70313305b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rerank(D)","metadata":{"_uuid":"f8e3cf66-ee10-4bc4-8001-94c115cdc024","_cell_guid":"9f9f58bc-7eb4-4929-904c-7dabd3d07362","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"edges = dist_to_edges(D)","metadata":{"_uuid":"2bec7d27-7ac6-45b7-8785-3551a53cb215","_cell_guid":"a963be5e-168a-4262-abbb-439bc19b6288","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups, groups_p = edges_to_groups(edges, len(D))\nfor pos, size_pct in get_targets_shape(train_df):\n    chisel(groups, groups_p, pos, int(size_pct * len(groups)))","metadata":{"_uuid":"4a7a3120-8e3d-42c7-8dd2-98aa619c87dd","_cell_guid":"79409dfd-0ab4-4983-ad43-12436be7c86d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matches = [' '.join(test_df.iloc[g].posting_id.to_list()) for g in groups]\ntest_df['matches'] = matches\n\ntest_df[['posting_id','matches']].to_csv('submission.csv',index=False)","metadata":{"_uuid":"70a4b021-d4dd-4266-9fe3-76afd4827239","_cell_guid":"c0fc32bc-c424-4e84-9927-6da8e23e3c90","collapsed":false,"papermill":{"duration":0.203316,"end_time":"2021-04-22T16:24:51.958678","exception":false,"start_time":"2021-04-22T16:24:51.755362","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('submission.csv').head()","metadata":{"_uuid":"18873ab2-7d6d-4758-bf92-e2bf9b189042","_cell_guid":"0e112eb9-6f2d-41a9-8427-8c220290fafe","collapsed":false,"papermill":{"duration":0.072363,"end_time":"2021-04-22T16:24:52.056043","exception":false,"start_time":"2021-04-22T16:24:51.98368","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"9125057f-3ee4-4ed7-bd29-e5413d25ea1e","_cell_guid":"72ef3a00-c056-497c-84ce-c7ba080b6762","collapsed":false,"papermill":{"duration":0.024336,"end_time":"2021-04-22T16:24:52.104931","exception":false,"start_time":"2021-04-22T16:24:52.080595","status":"completed"},"tags":[],"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}