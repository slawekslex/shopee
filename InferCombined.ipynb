{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\nimport sklearn.metrics as skm\nfrom tqdm.notebook import tqdm\nimport sklearn.feature_extraction.text\nfrom transformers import (BertTokenizer, BertModel,\n                          DistilBertTokenizer, DistilBertModel)\nimport gc","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shopee_utils import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OUTPUT_CLASSES=11014\nTAKE_PAIRS = 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRIAL_RUN=False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf = {\n    'bs':64,\n    'arch':resnet34,\n    'split':0\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = Path('../input/shopee-product-matching')\nimage_model_file  = '../input/shopee-models/resnet34_arcface.pth'\ntext_model_file  = '../input/shopee-models/bert823val.pth'\nBERT_PATH = '../input/bertindo15g'\nif not PATH.is_dir():\n    PATH = Path('/home/slex/data/shopee')\n    image_model_file ='models/resnet34_arcface.pth'\n    text_model_file='./models/bert823val.pth'\n    BERT_PATH = './bert_indonesian'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hash_label(x):\n    x = (13*x)%10000\n    return x // 2000\ntrain_df = pd.read_csv(PATH/'train.csv')\ntrain_df['split']=train_df.label_group.apply(hash_label)\ntrain_df['is_valid'] = train_df.split==conf['split']\nvalid_df=train_df[train_df.is_valid==True].copy().reset_index()\nvalid_df = add_target_groups(valid_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TEXT","metadata":{}},{"cell_type":"code","source":"class ArcFaceClassifier(nn.Module):\n    def __init__(self, in_features, output_classes):\n        super().__init__()\n        emb_dim=768\n        mid_size = 512\n        self.initial_layers=nn.Sequential(\n            nn.BatchNorm1d(emb_dim),\n            nn.Dropout(.25))\n        self.W = nn.Parameter(torch.Tensor(emb_dim, output_classes))\n        nn.init.kaiming_uniform_(self.W)\n    def forward(self, x):\n        x = self.initial_layers(x)\n        x_norm = F.normalize(x)\n        W_norm = F.normalize(self.W, dim=0)\n        return x_norm @ W_norm\n    \n    \ndef arcface_loss(cosine, targ, m=.5, s=30):\n    cosine = cosine.clip(-1+1e-7, 1-1e-7) \n    arcosine = cosine.arccos()\n    arcosine += F.one_hot(targ, num_classes = OUTPUT_CLASSES) * m\n    cosine2 = arcosine.cos()\n    cosine2 *= s\n    return F.cross_entropy(cosine2, targ)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TitleTransform(Transform):\n    def __init__(self):\n        super().__init__()\n        self.tokenizer = BertTokenizer.from_pretrained(BERT_PATH)\n        \n        \n    def encodes(self, row):\n        text = row.title\n        encodings = self.tokenizer(text, padding = 'max_length', max_length=50, truncation=True,return_tensors='pt')\n        keys =['input_ids', 'attention_mask', 'token_type_ids'] \n        return tuple(encodings[key].squeeze() for key in keys)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfm = TitleTransform()\n\ndata_block = DataBlock(\n    blocks = (TransformBlock(type_tfms=tfm), \n              CategoryBlock(vocab=train_df.label_group.to_list())),\n    splitter=ColSplitter(),\n    get_y=ColReader('label_group'),\n    )\ntext_dls = data_block.dataloaders(train_df, bs=256,num_workers=16)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BertArcFace(nn.Module):\n    def __init__(self, bert_model):\n        super().__init__()\n        self.bert_model = bert_model\n        self.classifier = ArcFaceClassifier(768, OUTPUT_CLASSES)\n        self.outputEmbs = False\n    def forward(self, x):\n        output = self.bert_model(*x)\n        embeddings = output.last_hidden_state[:,0,:]#output.pooler_output\n        if self.outputEmbs:\n            return embeddings\n        return self.classifier(embeddings)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def new_text_model():\n    bert_model = BertModel.from_pretrained(BERT_PATH)\n    return BertArcFace(bert_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_text_pairs(dl):\n    model = new_text_model()\n    state = torch.load(text_model_file)\n    model.load_state_dict(state['model'])\n    model.eval().cuda()\n    model.outputEmbs=True\n    embs, ys = embs_from_model(model, dl)\n    target_matrix = ys[:,None]==ys[None,:]\n    groups = [torch.where(t)[0].tolist() for t in target_matrix]\n    dists, inds = get_nearest(embs, do_chunk(embs))\n    pairs = sorted_pairs(dists, inds)[:len(embs)*10]\n    return pairs, groups","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pairs, groups = generate_text_pairs(text_dls.valid)\n# _=build_from_pairs(pairs, groups, True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## IMAGE\n","metadata":{}},{"cell_type":"code","source":"class ArcFaceImgClassifier(nn.Module):\n    def __init__(self, in_features, output_classes):\n        super().__init__()\n        self.W = nn.Parameter(torch.Tensor(in_features, output_classes))\n        nn.init.kaiming_uniform_(self.W)\n    def forward(self, x):\n        x_norm = F.normalize(x)\n        W_norm = F.normalize(self.W, dim=0)\n        return x_norm @ W_norm\n    \nclass ResnetArcFace(nn.Module):\n    def __init__(self, output_classes):\n        super().__init__()\n        self.body = create_body(conf['arch'], cut=-2, pretrained=False)\n        nf = num_features_model(nn.Sequential(*self.body.children()))\n        self.after_conv=nn.Sequential(\n            AdaptiveConcatPool2d(),\n            Flatten(),\n            nn.BatchNorm1d(nf*2),\n            nn.Dropout(.25))\n        self.classifier = ArcFaceImgClassifier(nf*2, output_classes)\n        self.outputEmbs = False\n        \n    def forward(self, x):\n        x = self.body(x)\n        embeddings = self.after_conv(x)\n        if self.outputEmbs:\n            return embeddings\n        return self.classifier(embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_file(row):\n    img =row.image\n    fn  = PATH/'train_images'/img\n    if not fn.is_file():\n        fn = PATH/'test_images'/img\n    return fn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_image_pairs(model, dl):\n    embs, _ = embs_from_resnet(model, dl)\n    dists, inds = get_nearest(embs, do_chunk_img(embs))\n    pairs = sorted_pairs(dists, inds)[:int(len(embs)*TAKE_PAIRS)]\n    return pairs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_block = DataBlock(blocks = (ImageBlock(), CategoryBlock(vocab=train_df.label_group.to_list())),\n                 splitter=ColSplitter(),\n                 get_y=ColReader('label_group'),\n                 get_x=get_img_file,\n                 item_tfms=Resize(460),\n                 batch_tfms=aug_transforms(size=224, min_scale=0.75),\n                 )\ndls_image = data_block.dataloaders(train_df, bs=conf['bs'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_image_pairs(dl):\n    model = ResnetArcFace(dls_image.c)\n    state = torch.load(image_model_file)\n    model.load_state_dict(state['model'])\n    model = model.cuda().eval()\n    model.outputEmbs = True\n    embs, ys = embs_from_model(model, dl)\n    target_matrix = ys[:,None]==ys[None,:]\n    groups = [torch.where(t)[0].tolist() for t in target_matrix]\n    dists, inds = get_nearest(embs, do_chunk(embs))\n    pairs = sorted_pairs(dists, inds)[:len(embs)*10]\n    return pairs, groups","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pairs, groups = generate_image_pairs(dls_image.valid)\n# _=build_from_pairs(pairs, groups, True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COMBINE","metadata":{}},{"cell_type":"code","source":"def weave(A,B):\n    R = list()\n    used = set()\n    for a,b in zip(A,B):\n        if a[:2] not in used:\n            R.append(a)\n            used.add(a[:2])\n        if b[:2] not in used:\n            R.append(b)\n            used.add(b[:2])\n    return R","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check on validation set","metadata":{}},{"cell_type":"code","source":"if TRIAL_RUN:\n    text_pairs, targets = generate_text_pairs(text_dls.valid)\n\n    img_pairs,_ = generate_image_pairs(dls_image.valid)\n\n    combined = weave(text_pairs, img_pairs)\n\n\n\n    _=build_from_pairs(text_pairs, targets)\n\n    _=build_from_pairs(img_pairs,targets)\n\n\n\n    _=build_from_pairs(combined, targets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run on the test set","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(PATH/'test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRIAL_RUN:\n    fake_test_df = train_df[['posting_id', 'image', 'image_phash', 'title', 'label_group']].copy()\n    fake_test_df = pd.concat([fake_test_df, fake_test_df])\n    fake_test_df = add_target_groups(fake_test_df)\n    test_df = fake_test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_pairs,_ = generate_text_pairs(text_dls.test_dl(test_df))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dl = dls_image.test_dl(test_df)\nimg_pairs,_ = generate_image_pairs(test_dl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined = weave(text_pairs, img_pairs)[:int(len(test_df)*TAKE_PAIRS)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'target' in test_df.columns.to_list():\n    _=build_from_pairs(text_pairs, test_df.target.to_list())\n    _=build_from_pairs(img_pairs, test_df.target.to_list())\n    _=build_from_pairs(combined, test_df.target.to_list())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups = [[] for _ in range(len(test_df))]\nfor x,y,v in combined:\n    groups[x].append(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matches = [' '.join(test_df.iloc[g].posting_id.to_list()) for g in groups]\ntest_df['matches'] = matches\n\ntest_df[['posting_id','matches']].to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('submission.csv').head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}