{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "personalized-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import spacy\n",
    "\n",
    "import seaborn\n",
    "from shopee_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "experienced-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "academic-morgan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "train_df = add_splits(pd.read_csv(PATH/'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "complex-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_RE = re.compile(r'[\\w]+')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def tokenize_text_simple_regex(txt, min_token_size=2):\n",
    "    txt = str(txt).lower()\n",
    "    all_tokens = TOKEN_RE.findall(txt)\n",
    "    return [wordnet_lemmatizer.lemmatize(token, pos=\"v\") for token in all_tokens if len(token) >= min_token_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "front-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(texts, tokenizer=tokenize_text_simple_regex, **tokenizer_kwargs):\n",
    "    return [tokenizer(text, **tokenizer_kwargs) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "naughty-basics",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3782926ae7bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wordnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "polyphonic-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = tokenize_corpus(train_df.title.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "registered-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "        sentences=corpus,\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "convenient-murray",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word2VecKeyedVectors' object has no attribute 'index_to_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-27b9bd92ede9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'jam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tangan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wanita'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xiaomi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'redmi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'note'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'somebymi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yuja'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'niacin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'100'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ml'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgensim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_words\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgensim_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgensim_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-27b9bd92ede9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'jam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tangan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wanita'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xiaomi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'redmi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'note'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'somebymi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yuja'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'niacin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'100'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ml'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgensim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_words\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgensim_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgensim_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Word2VecKeyedVectors' object has no attribute 'index_to_key'"
     ]
    }
   ],
   "source": [
    "test_words = ['jam', 'tangan', 'wanita', 'xiaomi','redmi','note', 'somebymi', 'yuja', 'niacin', '100', 'ml']\n",
    "gensim_words = [w for w in test_words if w in model.wv.index_to_key]\n",
    "gensim_vectors = np.stack([model.wv[w] for w in gensim_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-equity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python38564bitfastaicondad52d12c5a30a4725bf9d3e235cf1271c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
