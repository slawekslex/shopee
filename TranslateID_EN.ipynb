{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sufficient-remedy",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "addressed-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fiscal-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shopee_utils import *\n",
    "from train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cultural-parker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('127.0.0.1', 5678)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import debugpy\n",
    "debugpy.listen(5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "commercial-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-id-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parliamentary-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_model = AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-id-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "infinite-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_model=txt_model.cuda().eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "given-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('/home/slex/data/shopee')\n",
    "train_df = pd.read_csv(PATH/'train_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "certified-danger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translating texts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d937b5aab7a4d6597df8207ea81b0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trans_texts = []\n",
    "CHUNK = 50\n",
    "\n",
    "print('translating texts')\n",
    "CTS = len(train_df)//CHUNK\n",
    "if len(train_df)%CHUNK!=0: CTS += 1\n",
    "for i,j in tqdm(enumerate(range(CTS)), total=CTS):\n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b,len(train_df))\n",
    "    input_ids = tokenizer(list(train_df.iloc[a:b].title.values), return_tensors=\"pt\", truncation=True, padding=True).input_ids.cuda()\n",
    "    outputs = txt_model.generate(input_ids=input_ids, num_return_sequences=1)    \n",
    "    val = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    trans_texts.extend(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quality-transport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34250"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "patent-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['en_title']=trans_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "victorian-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(PATH/'train_trans.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "direct-columbus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>en_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4.5 m ORIGINAL / DOUBLE FOAM TAPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>TTS Thief Canned Pork Luncheon Meat 397 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Campur - Leher Kancing (DPT001-00) Batik karakter Alhadi</td>\n",
       "      <td>Batik Short Arm - Random Motive / Mixed - Snap Neck (DPT001-00) Batik character Alhadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34245</th>\n",
       "      <td>Masker Bahan Kain Spunbond Non Woven 75 gsm 3 ply lapis Bisa Dicuci</td>\n",
       "      <td>Spunbond Material Mask Non Woven 75 gsm 3 ply layer washable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34246</th>\n",
       "      <td>MamyPoko Pants Royal Soft - S 70 - Popok Celana</td>\n",
       "      <td>MamyPoko Pants Royal Soft - S 70 - Popok Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34247</th>\n",
       "      <td>KHANZAACC Robot RE101S 1.2mm Subwoofer Bass Metal Wired Headset</td>\n",
       "      <td>KHANZAACC Robot RE101S 1.2mm Subwoofer Bass Metal Wired Headset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34248</th>\n",
       "      <td>Kaldu NON MSG HALAL Mama Kamu Ayam Kampung , Sapi Lokal,  Jamur (Bkn Alsultan / Biocell)</td>\n",
       "      <td>Your Mama's NON MSG Hall Chicken Village, Local Cows, Mushrooms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34249</th>\n",
       "      <td>FLEX TAPE PELAPIS BOCOR / ISOLASI AJAIB / ANTI BOCOR</td>\n",
       "      <td>FLEX TAPE PALAPIS BOCOR / ISOLIATION AJAIB / ANTI BOCOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34250 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    title  \\\n",
       "0                                                                               Paper Bag Victoria Secret   \n",
       "1                                            Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DOUBLE FOAM TAPE   \n",
       "2                                                             Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3      Daster Batik Lengan pendek - Motif Acak / Campur - Leher Kancing (DPT001-00) Batik karakter Alhadi   \n",
       "4                                                                       Nescafe \\xc3\\x89clair Latte 220ml   \n",
       "...                                                                                                   ...   \n",
       "34245                                 Masker Bahan Kain Spunbond Non Woven 75 gsm 3 ply lapis Bisa Dicuci   \n",
       "34246                                                     MamyPoko Pants Royal Soft - S 70 - Popok Celana   \n",
       "34247                                     KHANZAACC Robot RE101S 1.2mm Subwoofer Bass Metal Wired Headset   \n",
       "34248            Kaldu NON MSG HALAL Mama Kamu Ayam Kampung , Sapi Lokal,  Jamur (Bkn Alsultan / Biocell)   \n",
       "34249                                                FLEX TAPE PELAPIS BOCOR / ISOLASI AJAIB / ANTI BOCOR   \n",
       "\n",
       "                                                                                     en_title  \n",
       "0                                                                   Paper Bag Victoria Secret  \n",
       "1                                Double Tape 3M VHB 12 mm x 4.5 m ORIGINAL / DOUBLE FOAM TAPE  \n",
       "2                                                  TTS Thief Canned Pork Luncheon Meat 397 gr  \n",
       "3      Batik Short Arm - Random Motive / Mixed - Snap Neck (DPT001-00) Batik character Alhadi  \n",
       "4                                                           Nescafe \\xc3\\x89clair Latte 220ml  \n",
       "...                                                                                       ...  \n",
       "34245                            Spunbond Material Mask Non Woven 75 gsm 3 ply layer washable  \n",
       "34246                                          MamyPoko Pants Royal Soft - S 70 - Popok Pants  \n",
       "34247                         KHANZAACC Robot RE101S 1.2mm Subwoofer Bass Metal Wired Headset  \n",
       "34248                        Your Mama's NON MSG Hall Chicken Village, Local Cows, Mushrooms.  \n",
       "34249                                 FLEX TAPE PALAPIS BOCOR / ISOLIATION AJAIB / ANTI BOCOR  \n",
       "\n",
       "[34250 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trans_df =pd.read_csv(PATH/'train_trans.csv')\n",
    "trans_df[['title', 'en_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "enormous-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(list(train_df.iloc[0:4].title.values), return_tensors=\"pt\", truncation=True, padding=True).input_ids.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "revised-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nonprofit-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = txt_model.generate(input_ids, output_hidden_states=True, num_beam_groups=1, num_beams=1,return_dict_in_generate=True, max_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "directed-editor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.encoder_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "synthetic-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_state = torch.cat([t.mean(dim=1) for t in outputs.encoder_hidden_states], dim=1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "organized-hobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3584])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(outputs.decoder_hidden_states[0], dim=2).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-victor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continental-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcFaceClassifier(nn.Module):\n",
    "    def __init__(self, in_features, output_classes):\n",
    "        super().__init__()\n",
    "        self.initial_layers=nn.Sequential(\n",
    "\n",
    "            nn.BatchNorm1d(in_features),\n",
    "            nn.Dropout(.25))\n",
    "        self.W = nn.Parameter(torch.Tensor(in_features, output_classes))\n",
    "        nn.init.kaiming_uniform_(self.W)\n",
    "    def forward(self, x):\n",
    "        x = self.initial_layers(x)\n",
    "        x_norm = F.normalize(x)\n",
    "        W_norm = F.normalize(self.W, dim=0)\n",
    "        return x_norm @ W_norm\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "proprietary-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleTransform(Transform):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-id-en')\n",
    "        \n",
    "        \n",
    "    def encodes(self, row):\n",
    "        text = row.title\n",
    "        encodings = self.tokenizer(text, padding = 'max_length', max_length=50, truncation=True,return_tensors='pt')\n",
    "        return encodings['input_ids'].squeeze(), encodings['attention_mask'].squeeze(), torch.tensor(54795).view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "maritime-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = TitleTransform()\n",
    "\n",
    "data_block = DataBlock(\n",
    "    blocks = (TransformBlock(type_tfms=tfm), \n",
    "              CategoryBlock(vocab=train_df.label_group.to_list())),\n",
    "    splitter=ColSplitter(),\n",
    "    get_y=ColReader('label_group'),\n",
    "    )\n",
    "dls = data_block.dataloaders(train_df, bs=256,num_workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "constitutional-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SillyModel(nn.Module):\n",
    "    def __init__(self, text_model):\n",
    "        super().__init__()\n",
    "        self.text_model = text_model\n",
    "        embs_dim1, embs_dim2 = 4096, 1024\n",
    "        self.pooler = nn.Sequential(\n",
    "            nn.Linear(embs_dim1, embs_dim2),\n",
    "            nn.BatchNorm1d(embs_dim2),\n",
    "            nn.Dropout())\n",
    "        self.classifier = ArcFaceClassifier(embs_dim2, dls.c)\n",
    "        self.outputEmbs = False\n",
    "    def forward(self, x):\n",
    "        input_ids, attention_mask, decoder_input_ids = x\n",
    "        outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                                  decoder_input_ids=decoder_input_ids, output_hidden_states=True)\n",
    "        #enc_states = torch.mean(outputs['encoder_last_hidden_state'], dim=1)\n",
    "        enc_states = outputs['encoder_last_hidden_state'][:,0,:]\n",
    "        dec_states = torch.cat(outputs.decoder_hidden_states, dim=2).squeeze()\n",
    "        embeddings = torch.cat([enc_states, dec_states], dim=1)\n",
    "        embeddings = self.pooler(embeddings)\n",
    "        if self.outputEmbs:\n",
    "            return embeddings\n",
    "        return self.classifier(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "speaking-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "bx, by = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "unusual-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model():\n",
    "    txt_model = AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-id-en')\n",
    "    return SillyModel(txt_model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "amber-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_2way(model):\n",
    "    return L(params(model.text_model),\n",
    "            params(model.classifier)+params(model.pooler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bearing-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func=functools.partial(arcface_loss,m=.5)\n",
    "learn = Learner(dls,new_model(),  splitter=split_2way, loss_func=loss_func,  cbs = F1FromEmbs, metrics=FakeMetric(), train_bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fitted-handle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>F1 embeddings</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.795553</td>\n",
       "      <td>None</td>\n",
       "      <td>0.565353</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.683207</td>\n",
       "      <td>None</td>\n",
       "      <td>0.647583</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>F1 embeddings</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18.402208</td>\n",
       "      <td>None</td>\n",
       "      <td>0.681869</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.481159</td>\n",
       "      <td>None</td>\n",
       "      <td>0.697676</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16.569492</td>\n",
       "      <td>None</td>\n",
       "      <td>0.720971</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15.624162</td>\n",
       "      <td>None</td>\n",
       "      <td>0.733550</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>14.886375</td>\n",
       "      <td>None</td>\n",
       "      <td>0.748251</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>14.215281</td>\n",
       "      <td>None</td>\n",
       "      <td>0.755205</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>13.530007</td>\n",
       "      <td>None</td>\n",
       "      <td>0.760552</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>12.908889</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761603</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>12.341012</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761122</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>11.792464</td>\n",
       "      <td>None</td>\n",
       "      <td>0.765182</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11.300545</td>\n",
       "      <td>None</td>\n",
       "      <td>0.767525</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>10.823655</td>\n",
       "      <td>None</td>\n",
       "      <td>0.770461</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>10.363218</td>\n",
       "      <td>None</td>\n",
       "      <td>0.773617</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>9.952301</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769850</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>9.576521</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772193</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>9.240406</td>\n",
       "      <td>None</td>\n",
       "      <td>0.773413</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>9.000471</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772825</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>8.810121</td>\n",
       "      <td>None</td>\n",
       "      <td>0.774063</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>8.702633</td>\n",
       "      <td>None</td>\n",
       "      <td>0.774467</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>8.658486</td>\n",
       "      <td>None</td>\n",
       "      <td>0.774321</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(20, 1e-2,lr_mult=10, freeze_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-graham",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python38564bitfastaicondad52d12c5a30a4725bf9d3e235cf1271c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
